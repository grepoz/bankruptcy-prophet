{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d073189c92ac37a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - read dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13973241d1c89f8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:13:26.284009Z",
     "start_time": "2024-04-16T17:13:25.126338Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Read in the dataset.\n",
    "dataset = pd.read_csv('ECL.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:14:00.106966Z",
     "start_time": "2024-04-16T17:13:59.780243Z"
    }
   },
   "id": "8b8600924b3964d3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:14:00.683051Z",
     "start_time": "2024-04-16T17:14:00.665850Z"
    }
   },
   "id": "9a549ae8aa6c3d34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170139\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the subset of labelled 10Ks\n",
    "prediction_subset = dataset.loc[(dataset['can_label'] == True) & (dataset['qualified'] == 'Yes')].reset_index(drop=True)\n",
    "prediction_subset['cik'] = prediction_subset['cik'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:30:28.375636Z",
     "start_time": "2024-04-14T19:30:28.332669Z"
    }
   },
   "id": "3f5146bda4c49451",
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "qualified_possible_values = dataset.loc[(dataset['can_label'] == False)]\n",
    "print(len(qualified_possible_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:30:29.398827Z",
     "start_time": "2024-04-14T19:30:29.395353Z"
    }
   },
   "id": "395abb1ce06e8386",
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prediction_subset.drop(columns=['can_label'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:30:30.280139Z",
     "start_time": "2024-04-14T19:30:30.261140Z"
    }
   },
   "id": "ef848e8dc6779739",
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled 10Ks: 84652\n"
     ]
    }
   ],
   "source": [
    "print('Number of labelled 10Ks:', len(prediction_subset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:30:31.655681Z",
     "start_time": "2024-04-14T19:30:31.652708Z"
    }
   },
   "id": "5d33958649dafa31",
   "execution_count": 209
  },
  {
   "cell_type": "markdown",
   "source": [
    "**-> Dataset is ready for further processing**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a5006ba59a1510"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique companies: 9143\n",
      "    cik                           company\n",
      "0  1750                          AAR CORP\n",
      "1  1800               ABBOTT LABORATORIES\n",
      "2  2024                 ACE HARDWARE CORP\n",
      "3  2034                        ACETO CORP\n",
      "4  2135  AFFILIATED COMPUTER SERVICES INC\n",
      "5  2178    ADAMS RESOURCES & ENERGY, INC.\n",
      "6  2488        ADVANCED MICRO DEVICES INC\n",
      "7  2491          BALLY TECHNOLOGIES, INC.\n",
      "8  2601                      AEROFLEX INC\n",
      "9  2852                         AGWAY INC\n"
     ]
    }
   ],
   "source": [
    "# getting unique companies by cik\n",
    "unique_companies = prediction_subset.groupby('cik').agg(company=('company', 'last')).reset_index()\n",
    "print(f\"Number of unique companies: {len(unique_companies)}\")\n",
    "print(unique_companies.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T20:18:12.150529Z",
     "start_time": "2024-04-14T20:18:12.137967Z"
    }
   },
   "id": "fd7da14ea51f5fd9",
   "execution_count": 237
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - looking into data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50cfd544ad5aea95"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies with filing date: 9143\n",
      "    cik                           company filing_date\n",
      "0  1750                          AAR CORP  2021-07-21\n",
      "1  1800               ABBOTT LABORATORIES  2021-02-19\n",
      "2  2024                 ACE HARDWARE CORP  2003-03-24\n",
      "3  2034                        ACETO CORP  2018-09-28\n",
      "4  2135  AFFILIATED COMPUTER SERVICES INC  2009-08-27\n",
      "5  2178    ADAMS RESOURCES & ENERGY, INC.  2020-03-06\n",
      "6  2488        ADVANCED MICRO DEVICES INC  2021-01-29\n",
      "7  2491          BALLY TECHNOLOGIES, INC.  2014-08-29\n",
      "8  2601                      AEROFLEX INC  2006-09-13\n",
      "9  2852                         AGWAY INC  2002-09-30\n"
     ]
    }
   ],
   "source": [
    "companies_with_last_filing_date = prediction_subset.groupby('cik').agg(\n",
    "    company=('company', 'last'),\n",
    "    filing_date=('filing_date', 'last')\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Number of companies with filing date: {len(companies_with_last_filing_date)}\")\n",
    "print(companies_with_last_filing_date.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:30:43.014629Z",
     "start_time": "2024-04-14T19:30:43.000613Z"
    }
   },
   "id": "88601d116d0b3eaf",
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086\n"
     ]
    }
   ],
   "source": [
    "companies_with_last_filing_date_after_2021 = companies_with_last_filing_date[companies_with_last_filing_date['filing_date'] > '2021-01-01']\n",
    "print(len(companies_with_last_filing_date_after_2021))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:31:05.441699Z",
     "start_time": "2024-04-14T19:31:05.436858Z"
    }
   },
   "id": "e8d56e457bcddca3",
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n"
     ]
    }
   ],
   "source": [
    "companies_with_last_filing_date_before_2010 = companies_with_last_filing_date[companies_with_last_filing_date['filing_date'] < '2010-01-01']\n",
    "print(len(companies_with_last_filing_date_before_2010))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:31:09.473810Z",
     "start_time": "2024-04-14T19:31:09.468532Z"
    }
   },
   "id": "854d3b490579451d",
   "execution_count": 214
  },
  {
   "cell_type": "markdown",
   "source": [
    "Around third of companies have last filing date greater than 2021 - the last year included within the dataset that could be labelled (due to unsupported Florida-UCLA-LoPucki database)\n",
    "\n",
    "Almost half has last filing before 2010"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff914307d399015"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - looking for tickers using gurufocus.com\n",
    "\n",
    "I need to get tickers and stockid for companies - to further download financial data from gurufocus.com (or look for different data provider). Also I focus on NYSE and NASDAQ exchanges."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d6880130f44f942"
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'authority': 'www.google.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:14:13.667417Z",
     "start_time": "2024-04-16T17:14:13.569232Z"
    }
   },
   "id": "92deb4cf39e021a7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "pattern = re.compile(r\"[\\\\/.,\\\"]\") \n",
    "\n",
    "def clear_company_name(company_name):\n",
    "    company_name = company_name.lower()\n",
    "    company_name = re.sub(r\"[\\\\/(].*\", '', company_name)\n",
    "    company_name = pattern.sub('', company_name)\n",
    "    company_name = company_name.strip()\n",
    "    company_name = company_name.replace(' ', '+')\n",
    "    return company_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:14:16.337983Z",
     "start_time": "2024-04-16T17:14:16.331481Z"
    }
   },
   "id": "9d200a561a4ff3a3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexander+&+alexander+services+inc\n"
     ]
    }
   ],
   "source": [
    "print(clear_company_name(\"ALEXANDER & ALEXANDER SERVICES INC\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T19:50:20.921003Z",
     "start_time": "2024-04-14T19:50:20.918105Z"
    }
   },
   "id": "e092072e8c01a299",
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found companies count: 5774: 100%|██████████| 9143/9143 [3:14:41<00:00,  1.28s/it]  \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "found_companies_count = 0\n",
    "\n",
    "companies_with_not_found_tickers_list = []\n",
    "companies_with_not_found_tickers_with_exception = []\n",
    "\n",
    "pbar = tqdm(unique_companies.values.tolist())\n",
    "\n",
    "exceptions_list = []\n",
    "\n",
    "for cik, company in pbar:\n",
    "\n",
    "    cleared_company_name = clear_company_name(company)\n",
    "    url = f'https://www.gurufocus.com/reader/_api/_search?v=1.4.13&text={cleared_company_name}'\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response_json = response.json()\n",
    "        except Exception as ex:\n",
    "            companies_with_not_found_tickers_with_exception.append({'cik': cik, 'company': company})\n",
    "            exceptions_list.append(ex)\n",
    "            time.sleep(0.7)\n",
    "            continue\n",
    "\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "        if len(response_json) == 0:\n",
    "            has_company_name_changed = False\n",
    "            if '+inc' in cleared_company_name:\n",
    "                cleared_company_name = cleared_company_name.replace('+inc', '')\n",
    "                has_company_name_changed = True\n",
    "            if '+co' in cleared_company_name:\n",
    "                # may match 'co' in any word\n",
    "                cleared_company_name = cleared_company_name.replace('+co', '+company')\n",
    "                has_company_name_changed = True\n",
    "            if '+llc' in cleared_company_name:\n",
    "                cleared_company_name = cleared_company_name.replace('+llc', '')\n",
    "                has_company_name_changed = True\n",
    "            cleared_company_name = cleared_company_name.strip()\n",
    "            \n",
    "            if has_company_name_changed:\n",
    "                url = f'https://www.gurufocus.com/reader/_api/_search?v=1.4.13&text={cleared_company_name}'\n",
    "                try:\n",
    "                    response = requests.get(url, headers=headers)\n",
    "                    response_json = response.json()\n",
    "                except Exception as ex:\n",
    "                    companies_with_not_found_tickers_with_exception.append({'cik': cik, 'company': company})\n",
    "                    exceptions_list.append(ex)\n",
    "                    time.sleep(0.7)\n",
    "                    continue\n",
    "                \n",
    "            if len(response_json) == 0:\n",
    "                companies_with_not_found_tickers_list.append({'cik': cik, 'company': company})\n",
    "                continue\n",
    "        \n",
    "        is_company_found = False\n",
    "        matched_type_counter = 0\n",
    "        for entry in response_json:\n",
    "            if entry['type'] not in ('stock', 'delisted'):\n",
    "                if matched_type_counter > 0:\n",
    "                    break\n",
    "                continue\n",
    "                \n",
    "            exchange = entry['data']['exchange']\n",
    "            if exchange in ('NYSE', 'NAS', 'DELISTED'):\n",
    "                ticker = entry['data']['symbol']\n",
    "                stockid = entry['data']['stockid']\n",
    "                # gurufocus_company_name = entry['data']['company']\n",
    "                \n",
    "                if matched_type_counter == 0:\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'ticker'] = ticker\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'exchange'] = exchange\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'gurufocus-stockid'] = stockid\n",
    "                    # prediction_subset.loc[prediction_subset['cik'] == cik, 'gurufocus-company-name'] = gurufocus_company_name\n",
    "                    \n",
    "                    \n",
    "                    is_company_found = True\n",
    "                    found_companies_count += 1\n",
    "                    pbar.set_description(f\"Found companies count: {found_companies_count}\")\n",
    "                    matched_type_counter += 1\n",
    "                    \n",
    "                elif matched_type_counter == 1:\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'second-match-ticker'] = ticker\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'second-match-exchange'] = exchange\n",
    "                    prediction_subset.loc[prediction_subset['cik'] == cik, 'second-match-gurufocus-stockid'] = stockid\n",
    "                    # prediction_subset.loc[prediction_subset['cik'] == cik, 'second-match-gurufocus-company-name'] = gurufocus_company_name\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        if not is_company_found:\n",
    "            companies_with_not_found_tickers_list.append({'cik': cik, 'company': company})\n",
    "            \n",
    "    except Exception as ex:\n",
    "        companies_with_not_found_tickers_with_exception.append({'cik': cik, 'company': company})\n",
    "        exceptions_list.append(ex)\n",
    "        time.sleep(0.7)\n",
    "        \n",
    "companies_with_not_found_tickers_df = pd.DataFrame(companies_with_not_found_tickers_list)\n",
    "companies_with_not_found_tickers_with_exception_df = pd.DataFrame(companies_with_not_found_tickers_with_exception)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:19:56.584393Z",
     "start_time": "2024-04-14T10:05:15.327901Z"
    }
   },
   "id": "f4488259adfeb373",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies with found tickers: 5774\n",
      "Number of companies with not found tickers: 3369\n",
      "Number of companies with exceptions: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of companies with found tickers: {found_companies_count}\")\n",
    "print(f\"Number of companies with not found tickers: {len(companies_with_not_found_tickers_list)}\")\n",
    "print(f\"Number of companies with exceptions: {len(companies_with_not_found_tickers_with_exception_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:22.424548Z",
     "start_time": "2024-04-14T13:20:22.419028Z"
    }
   },
   "id": "4764fa4e33c2914a",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datetime_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "prediction_subset.to_csv(f'ECL_with_ticker_{datetime_now}.csv')\n",
    "companies_with_not_found_tickers_df.to_csv(f'ECL_companies_with_not_found_tickers_{datetime_now}.csv')\n",
    "companies_with_not_found_tickers_with_exception_df.to_csv(f'ECL_companies_with_not_found_tickers_with_exception_{datetime_now}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:34.245321Z",
     "start_time": "2024-04-14T13:20:33.237871Z"
    }
   },
   "id": "3a95ff8f9d63448",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# move ticker and exchange to the front of the dataset\n",
    "# prediction_subset = prediction_subset[['ticker', 'company', 'exchange', 'label', 'filename', 'bankruptcy_prediction_split', 'filing_date']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-08T08:16:48.952513Z"
    }
   },
   "id": "baceab88ab174f93",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data from gurufocus.com\n",
    "\n",
    "#### Download data for companies with one ticker (then for companies with two tickers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76d76f91e5305662"
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_subset = pd.read_csv('ECL_with_ticker_2024-04-14_15-20-33.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:26:58.218391Z",
     "start_time": "2024-04-16T17:26:58.001925Z"
    }
   },
   "id": "9b6870e7215bd9dd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_subset_with_gurufocus_data = prediction_subset.groupby('cik').agg(\n",
    "    company=('company', 'last'),\n",
    "    ticker=('ticker', 'last'),\n",
    "    second_match_ticker=('second-match-ticker', 'last'),\n",
    "    gurufocus_stockid=('gurufocus-stockid', 'last'),\n",
    "    second_match_gurufocus_stockid=('second-match-gurufocus-stockid', 'last')\n",
    ").reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:26:59.723294Z",
     "start_time": "2024-04-16T17:26:59.697248Z"
    }
   },
   "id": "8d9701da8b984250",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# get companies with one ticker\n",
    "companies_with_one_ticker = prediction_subset_with_gurufocus_data[prediction_subset_with_gurufocus_data['ticker'].notnull() & prediction_subset_with_gurufocus_data['second_match_ticker'].isnull()]\n",
    "print(len(companies_with_one_ticker))\n",
    "print(companies_with_one_ticker.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:27:15.082069Z",
     "start_time": "2024-04-16T17:27:15.072669Z"
    }
   },
   "id": "2f3caaa0ad91e2cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n",
      "     cik                            company ticker second_match_ticker  \\\n",
      "0   1750                           AAR CORP    AIR                None   \n",
      "1   1800                ABBOTT LABORATORIES    ABT                None   \n",
      "6   2488         ADVANCED MICRO DEVICES INC    AMD                None   \n",
      "7   2491           BALLY TECHNOLOGIES, INC.    BYI                None   \n",
      "8   2601                       AEROFLEX INC   ARXX                None   \n",
      "10  2969  AIR PRODUCTS & CHEMICALS INC /DE/    APD                None   \n",
      "16  3197            CECO ENVIRONMENTAL CORP   CECO                None   \n",
      "19  3370          IKON OFFICE SOLUTIONS INC    IKN                None   \n",
      "21  3453                       MATSON, INC.   MATX                None   \n",
      "23  3545                        ALICO, INC.   ALCO                None   \n",
      "\n",
      "   gurufocus_stockid second_match_gurufocus_stockid  \n",
      "0             US06AR                           None  \n",
      "1             US066X                           None  \n",
      "6             US022E                           None  \n",
      "7             US06R5                           None  \n",
      "8             US026H                           None  \n",
      "10            US06DU                           None  \n",
      "16            US02K6                           None  \n",
      "19            US07ZK                           None  \n",
      "21            US08CS                           None  \n",
      "23            US0212                           None  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n",
      "    cik ticker gurufocus_stockid\n",
      "0  1750    AIR            US06AR\n",
      "1  1800    ABT            US066X\n",
      "2  2488    AMD            US022E\n",
      "3  2491    BYI            US06R5\n",
      "4  2601   ARXX            US026H\n",
      "5  2969    APD            US06DU\n",
      "6  3197   CECO            US02K6\n",
      "7  3370    IKN            US07ZK\n",
      "8  3453   MATX            US08CS\n",
      "9  3545   ALCO            US0212\n"
     ]
    }
   ],
   "source": [
    "companies_with_one_ticker_grouped_by_cik = companies_with_one_ticker.groupby('cik').agg(\n",
    "    ticker=('ticker', 'last'),\n",
    "    gurufocus_stockid=('gurufocus_stockid', 'last')\n",
    ").reset_index()\n",
    "print(len(companies_with_one_ticker_grouped_by_cik))\n",
    "print(companies_with_one_ticker_grouped_by_cik.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:01:45.246745Z",
     "start_time": "2024-04-14T21:01:45.238358Z"
    }
   },
   "id": "19201c56ae58d0ad",
   "execution_count": 267
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "table_ids = [\n",
    "    'financial_table_per_share_data',\n",
    "    'financial_table_ratios',\n",
    "    'financial_table_income_statement',\n",
    "    'financial_table_balance_sheet',\n",
    "    'financial_table_cashflow_statement',\n",
    "    'financial_table_valuation_ratios',\n",
    "    'financial_table_valuation_and_quality'\n",
    "]\n",
    "\n",
    "options = webdriver.EdgeOptions()\n",
    "driver = webdriver.Edge(options=options)\n",
    "\n",
    "login_url = 'https://www.gurufocus.com/login'\n",
    "payload = {\n",
    "    \"username\": \"darekkruszel15@gmail.com\",\n",
    "    \"password\": \"=OcUZ*5&|{+l7-lGy:QMe4vHyF4X'~\"\n",
    "}\n",
    "\n",
    "def process_df(df):\n",
    "    df.drop(df.columns[1], axis=1, inplace=True) \n",
    "    return df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ],
   "id": "5850ed136bedf3c4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Success: 5071: 100%|██████████| 5115/5115 [5:47:17<00:00,  4.07s/it]   \n"
     ]
    }
   ],
   "source": [
    "# login\n",
    "driver.get(login_url)\n",
    "\n",
    "username = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'username')))\n",
    "password = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'password')))\n",
    "username.clear()\n",
    "password.clear()\n",
    "username.send_keys(payload['username'])\n",
    "password.send_keys(payload['password'])\n",
    "password.send_keys(Keys.RETURN)\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.LINK_TEXT, 'Articles')))\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "not_found_financial_data_with_exception = []\n",
    "not_found_financial_data_with_webdriver_timeout_exception = []\n",
    "success_count = 0\n",
    "\n",
    "pbar = tqdm(companies_with_one_ticker_grouped_by_cik.values.tolist())\n",
    "try:\n",
    "    for cik, ticker, stockid in pbar:\n",
    "        \n",
    "        url = f'https://www.gurufocus.com/stock/{stockid}/financials'\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(0.7)\n",
    "    \n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_per_share_data')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_ratios')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_income_statement')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_balance_sheet')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_cashflow_statement')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_valuation_ratios')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_valuation_and_quality')))\n",
    "            except Exception as ex:\n",
    "                not_found_financial_data_with_webdriver_timeout_exception.append([cik, stockid, ticker, str(ex)])\n",
    "                continue\n",
    "    \n",
    "            page_source = driver.page_source\n",
    "            with open(f'gurufocus-immediate-response-for-stockid/page_source-{cik}-{stockid}_{ticker}.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(page_source)\n",
    "            \n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "            gurufocus_company_name = soup.find('div', {'id': 'stock-header'}).find('div').text\n",
    "    \n",
    "            prediction_subset.loc[prediction_subset['cik'] == cik, 'gurufocus-company-name'] = gurufocus_company_name\n",
    "        \n",
    "            tables = soup.find_all('table')\n",
    "            \n",
    "            page_tables_ids = []\n",
    "            for table in tables:\n",
    "                try:\n",
    "                    table_id = table.get('id')\n",
    "                    if table_id:\n",
    "                        page_tables_ids.append(table_id)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if all(table_id not in page_tables_ids for table_id in table_ids):\n",
    "                pass\n",
    "            else:\n",
    "                merged_df = pd.DataFrame()\n",
    "                for table_id in table_ids:\n",
    "                    table = soup.find(id=table_id)\n",
    "                    df = pd.read_html(str(table), skiprows=1, header=0)[0]\n",
    "                    df = process_df(df)\n",
    "                    merged_df = pd.concat([merged_df, df])\n",
    "                    \n",
    "                merged_df.reset_index(drop=True, inplace=True)\n",
    "                merged_df.to_csv(f'financial_data/{cik}-{stockid}_{ticker}.csv')\n",
    "                \n",
    "                success_count += 1\n",
    "                pbar.set_description(f\"Success: {success_count}\")\n",
    "    \n",
    "        except Exception as ex:\n",
    "            not_found_financial_data_with_exception.append([cik, stockid, ticker, str(ex)])\n",
    "\n",
    "finally:\n",
    "    driver.close()\n",
    "    prediction_subset.to_csv(f'ECL_with_ticker_{datetime_now}.csv')\n",
    "\n",
    "    with open('not_found_financial_data_with_exception.json', 'w') as file:\n",
    "        json.dump(list(not_found_financial_data_with_exception), file)\n",
    "        \n",
    "    with open('not_found_financial_data_with_webdriver_timeout_exception.json', 'w') as file:\n",
    "        json.dump(list(not_found_financial_data_with_webdriver_timeout_exception), file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T03:22:23.616165Z",
     "start_time": "2024-04-14T21:34:57.571580Z"
    }
   },
   "id": "86dec1a4998aece7",
   "execution_count": 278
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of companies with not found financial data with exception: {len(not_found_financial_data_with_exception)}\")\n",
    "print(f\"Number of companies with not found financial data with webdriver timeout exception: {len(not_found_financial_data_with_webdriver_timeout_exception)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f9e28be126fbdac",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get companies with two tickers",
   "id": "159f745b9bbdfbc"
  },
  {
   "cell_type": "code",
   "source": [
    "# get companies with two tickers\n",
    "\n",
    "companies_with_two_tickers = prediction_subset_with_gurufocus_data[prediction_subset_with_gurufocus_data['second_match_ticker'].notnull()]\n",
    "print(f\"Number of companies with two tickers: {len(companies_with_two_tickers)}\")\n",
    "print(companies_with_two_tickers.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:27:28.602522Z",
     "start_time": "2024-04-16T17:27:28.592412Z"
    }
   },
   "id": "c5f8e28f7acbf5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies with two tickers: 659\n",
      "     cik                             company     ticker second_match_ticker  \\\n",
      "15  3153                    ALABAMA POWER CO  ALPpQ.PFD         ALPROCL.PFD   \n",
      "18  3333                 ALBERTSONS INC /DE/        ACI                 ABS   \n",
      "20  3449  ALEXANDER & ALEXANDER SERVICES INC       ALEX                 AAL   \n",
      "35  4281               HOWMET AEROSPACE INC.        HWM         ARNCPRB.PFD   \n",
      "39  4447                           HESS CORP        HES           HESpA.PFD   \n",
      "56  5272  AMERICAN INTERNATIONAL GROUP, INC.        AIG               AIGWS   \n",
      "61  5611                            FINA INC        TFC                WYPT   \n",
      "64  5907                           AT&T CORP          T                  AT   \n",
      "91  7332              SOUTHWESTERN ENERGY CO        SWN            SWNC.PFD   \n",
      "97  7789                ASSOCIATED BANC-CORP        ASB           ASBpC.PFD   \n",
      "\n",
      "   gurufocus_stockid second_match_gurufocus_stockid  \n",
      "15            US0TUZ                         US06C0  \n",
      "18            US280P                         US066V  \n",
      "20            US06BL                         US066A  \n",
      "35            US0SWN                         US0SWO  \n",
      "39            US07TL                         US07TM  \n",
      "56            US06AN                         US06AO  \n",
      "61            US06JN                         US0628  \n",
      "64            US09O4                         US06FY  \n",
      "91            US09NC                         US09ND  \n",
      "97            US06FE                         US06FG  \n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "companies_with_two_tickers_flatten = companies_with_two_tickers[['cik', 'company', 'second_match_ticker', 'second_match_gurufocus_stockid']]\n",
    "companies_with_two_tickers_flatten.columns = ['cik', 'company', 'ticker', 'gurufocus_stockid']\n"
   ],
   "id": "64920465bf2bb2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# login\n",
    "driver.get(login_url)\n",
    "\n",
    "username = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'username')))\n",
    "password = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'password')))\n",
    "username.clear()\n",
    "password.clear()\n",
    "username.send_keys(payload['username'])\n",
    "password.send_keys(payload['password'])\n",
    "password.send_keys(Keys.RETURN)\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.LINK_TEXT, 'Articles')))\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "not_found_financial_data_with_exception = []\n",
    "not_found_financial_data_with_webdriver_timeout_exception = []\n",
    "success_count = 0\n",
    "\n",
    "pbar = tqdm(companies_with_one_ticker_grouped_by_cik.values.tolist())\n",
    "try:\n",
    "    for cik, ticker, stockid in pbar:\n",
    "        \n",
    "        url = f'https://www.gurufocus.com/stock/{stockid}/financials'\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(0.7)\n",
    "    \n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_per_share_data')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_ratios')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_income_statement')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_balance_sheet')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_cashflow_statement')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_valuation_ratios')))\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.ID, 'financial_table_valuation_and_quality')))\n",
    "            except Exception as ex:\n",
    "                not_found_financial_data_with_webdriver_timeout_exception.append([cik, stockid, ticker, str(ex)])\n",
    "                continue\n",
    "    \n",
    "            page_source = driver.page_source\n",
    "            with open(f'gurufocus-immediate-response-for-stockid/page_source-{cik}-{stockid}_{ticker}.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(page_source)\n",
    "            \n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "            gurufocus_company_name = soup.find('div', {'id': 'stock-header'}).find('div').text\n",
    "    \n",
    "            prediction_subset.loc[prediction_subset['cik'] == cik, 'gurufocus-company-name'] = gurufocus_company_name\n",
    "        \n",
    "            tables = soup.find_all('table')\n",
    "            \n",
    "            page_tables_ids = []\n",
    "            for table in tables:\n",
    "                try:\n",
    "                    table_id = table.get('id')\n",
    "                    if table_id:\n",
    "                        page_tables_ids.append(table_id)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if all(table_id not in page_tables_ids for table_id in table_ids):\n",
    "                pass\n",
    "            else:\n",
    "                merged_df = pd.DataFrame()\n",
    "                for table_id in table_ids:\n",
    "                    table = soup.find(id=table_id)\n",
    "                    df = pd.read_html(str(table), skiprows=1, header=0)[0]\n",
    "                    df = process_df(df)\n",
    "                    merged_df = pd.concat([merged_df, df])\n",
    "                    \n",
    "                merged_df.reset_index(drop=True, inplace=True)\n",
    "                merged_df.to_csv(f'financial_data/{cik}-{stockid}_{ticker}.csv')\n",
    "                \n",
    "                success_count += 1\n",
    "                pbar.set_description(f\"Success: {success_count}\")\n",
    "    \n",
    "        except Exception as ex:\n",
    "            not_found_financial_data_with_exception.append([cik, stockid, ticker, str(ex)])\n",
    "\n",
    "finally:\n",
    "    driver.close()\n",
    "    prediction_subset.to_csv(f'ECL_with_ticker_{datetime_now}.csv')\n",
    "\n",
    "    with open('not_found_financial_data_with_exception.json', 'w') as file:\n",
    "        json.dump(list(not_found_financial_data_with_exception), file)\n",
    "        \n",
    "    with open('not_found_financial_data_with_webdriver_timeout_exception.json', 'w') as file:\n",
    "        json.dump(list(not_found_financial_data_with_webdriver_timeout_exception), file)"
   ],
   "id": "4eae074d3d987b99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'financial_data'\n",
    "\n",
    "found_data_tickers = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):  # Ensure it's a CSV file\n",
    "        found_data_tickers.append(filename.replace('.csv', ''))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T07:37:10.117012Z",
     "start_time": "2024-04-14T07:37:10.109815Z"
    }
   },
   "id": "b5c4e64f840e6675",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies with not found tickers: 9099\n"
     ]
    }
   ],
   "source": [
    "unique_companies_tickers = prediction_subset.groupby('cik').agg(ticker=('ticker', 'last')).reset_index()\n",
    "number_of_companies_with_not_found_tickers = unique_companies_tickers['ticker'].isnull().sum()\n",
    "print(f\"Number of companies with not found tickers: {number_of_companies_with_not_found_tickers}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:16:09.024873Z",
     "start_time": "2024-04-12T20:16:09.011433Z"
    }
   },
   "id": "e08cb42e823999d2",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4\n",
    "\n",
    "Checking tickers for all companies with edgar search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a238f1fb438bdf8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:26.983189Z",
     "start_time": "2024-04-13T06:43:26.406388Z"
    }
   },
   "id": "66486ee35e664dd1",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "partially_filled_dataset = pd.read_csv('ECL_with_ticker_2024-04-12_19-10-45.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:45:48.949745Z",
     "start_time": "2024-04-13T06:45:48.788259Z"
    }
   },
   "id": "f50130c2a04deec9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61973\n"
     ]
    }
   ],
   "source": [
    "print(partially_filled_dataset.count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:46:11.111413Z",
     "start_time": "2024-04-13T06:46:11.104582Z"
    }
   },
   "id": "6814e7d52ffbd1dc",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cik   company period_of_report   gvkey    datadate  \\\n",
      "0  1750  AAR CORP       1994-05-31  1004.0  31/05/1994   \n",
      "1  1750  AAR CORP       1995-05-31  1004.0  31/05/1995   \n",
      "2  1750  AAR CORP       1996-05-31  1004.0  31/05/1996   \n",
      "3  1750  AAR CORP       1997-05-31  1004.0  31/05/1997   \n",
      "4  1750  AAR CORP       1998-05-31  1004.0  31/05/1998   \n",
      "\n",
      "                                        filename  can_label qualified  label  \\\n",
      "0  /1994/1750_10K_1994_0000912057-94-002818.json       True       Yes  False   \n",
      "1  /1995/1750_10K_1995_0000912057-95-006316.json       True       Yes  False   \n",
      "2  /1996/1750_10K_1996_0000912057-96-018355.json       True       Yes  False   \n",
      "3  /1997/1750_10K_1997_0000912057-97-028915.json       True       Yes  False   \n",
      "4  /1998/1750_10K_1998_0001047469-98-032283.json       True       Yes  False   \n",
      "\n",
      "  bankruptcy_prediction_split bankruptcy_date_1 bankruptcy_date_2  \\\n",
      "0                       train               NaN               NaN   \n",
      "1                       train               NaN               NaN   \n",
      "2                       train               NaN               NaN   \n",
      "3                       train               NaN               NaN   \n",
      "4                       train               NaN               NaN   \n",
      "\n",
      "  bankruptcy_date_3 filing_date ticker exchange  \n",
      "0               NaN  1994-08-24    AIR     NYSE  \n",
      "1               NaN  1995-08-11    AIR     NYSE  \n",
      "2               NaN  1996-08-20    AIR     NYSE  \n",
      "3               NaN  1997-08-22    AIR     NYSE  \n",
      "4               NaN  1998-08-20    AIR     NYSE  \n"
     ]
    }
   ],
   "source": [
    "print(partially_filled_dataset.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:44:10.789778Z",
     "start_time": "2024-04-13T06:44:10.782231Z"
    }
   },
   "id": "2fba34a684b15121",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "companies_with_not_found_tickers = pd.read_csv('ECL_companies_with_not_found_tickers_2024-04-12_19-10-45.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:46:40.585656Z",
     "start_time": "2024-04-13T06:46:40.575516Z"
    }
   },
   "id": "ba25b2ae1b53b63c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pad_cik(cik):\n",
    "    cik = str(cik)\n",
    "    while len(cik) < 10:\n",
    "        cik = '0' + cik\n",
    "    return cik"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T06:47:54.957888Z",
     "start_time": "2024-04-13T06:47:54.953785Z"
    }
   },
   "id": "3045c505c7cbf89f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "not_found_tickers_count = 0\n",
    "exceptions_count = 0\n",
    "\n",
    "def process_row(row):\n",
    "    global not_found_tickers_count\n",
    "    global exceptions_count\n",
    "    \n",
    "    cik = row['cik']\n",
    "    company = row['company']\n",
    "    url = f'https://www.sec.gov/edgar/browse/?CIK={cik}&owner=exclude'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response_json = response.json()\n",
    "\n",
    "        indexes = []\n",
    "        cnt = 0\n",
    "        for exchange in response_json['exchanges']:\n",
    "            if exchange in ('NYSE', 'Nasdaq'):\n",
    "                indexes.append(cnt)\n",
    "                cnt += 1\n",
    "                \n",
    "        tickers = response_json['tickers']\n",
    "        \n",
    "        for index in indexes:\n",
    "            ticker = tickers[index]\n",
    "            exchange = response_json['exchanges'][index]\n",
    "            \n",
    "            partially_filled_dataset.loc[partially_filled_dataset['cik'] == cik, 'ticker'] = ticker\n",
    "        \n",
    "            if exchange == 'Nasdaq':\n",
    "                exchange = 'NAS'\n",
    "            partially_filled_dataset.loc[partially_filled_dataset['cik'] == cik, 'exchange'] = exchange\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error for company: {company}, cik: {cik} Error: {e}\")\n",
    "        exceptions_count += 1\n",
    "        return {'cik': cik, 'company': company}\n",
    "\n",
    "result_df  = unique_companies[:400].progress_apply(process_row, axis=1)\n",
    "result_df = result_df.dropna().reset_index(drop=True)\n",
    "companies_with_not_found_tickers_new = pd.DataFrame(result_df.tolist())\n",
    "\n",
    "driver.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1def124f41252cde",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
